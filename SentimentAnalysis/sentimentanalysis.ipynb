{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "## reading the dataset\n",
    "df = pd.read_csv('Restaurant_Reviews.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Liked\n",
       "0                           Wow... Loved this place.      1\n",
       "1                                 Crust is not good.      0\n",
       "2          Not tasty and the texture was just nasty.      0\n",
       "3  Stopped by during the late May bank holiday of...      1\n",
       "4  The selection on the menu was great and so wer...      1"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape ## shape of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Review  1000 non-null   object\n",
      " 1   Liked   1000 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 15.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info() ## info of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review    0\n",
       "Liked     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum() ## checking if null values exists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\win10\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the reviews\n",
    "corpus = []\n",
    "for i in range(0,1000):\n",
    "\n",
    "  # Cleaning special character from the reviews\n",
    "  review = re.sub(pattern='[^a-zA-Z]',repl=' ', string=df['Review'][i])\n",
    "\n",
    "  # Converting the entire review into lower case\n",
    "  review = review.lower()\n",
    "\n",
    "  # Tokenizing the review by words\n",
    "  review_words = review.split()\n",
    "\n",
    "  # Removing the stop words\n",
    "  review_words = [word for word in review_words if not word in set(stopwords.words('english'))]\n",
    "\n",
    "  # Stemming the words\n",
    "  ps = PorterStemmer()\n",
    "  review = [ps.stem(word) for word in review_words]\n",
    "\n",
    "  # Joining the stemmed words\n",
    "  review = ' '.join(review)\n",
    "\n",
    "  # Creating a corpus\n",
    "  corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wow love place',\n",
       " 'crust good',\n",
       " 'tasti textur nasti',\n",
       " 'stop late may bank holiday rick steve recommend love',\n",
       " 'select menu great price']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Bag of Words model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features=9000)\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "y = df.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Creating a pickle file for the CountVectorizer\n",
    "pickle.dump(cv, open('countvector.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "kfold = StratifiedKFold(n_splits=12)\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.68656716 0.68656716 0.76119403 0.70149254 0.68656716 0.64179104\n",
      " 0.73134328 0.7761194  0.63636364 0.63636364 0.78787879 0.72727273]\n",
      "70.49600482436304\n",
      "The accuracy of the Naive Bayes is 73.5\n",
      "[[59 38]\n",
      " [15 88]]\n"
     ]
    }
   ],
   "source": [
    "#GaussianNB\n",
    "gnb = GaussianNB(var_smoothing=1e-2)\n",
    "cv = cross_val_score(gnb,X_train,y_train,cv=kfold)\n",
    "print(cv)\n",
    "print(cv.mean()*100)\n",
    "gnb.fit(X_train,y_train)\n",
    "y_pred_gnb=gnb.predict(X_test)\n",
    "print('The accuracy of the Naive Bayes is', metrics.accuracy_score(y_pred_gnb,y_test)*100)\n",
    "cm=confusion_matrix(y_test, y_pred_gnb)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.74626866 0.80597015 0.71641791 0.7761194  0.79104478 0.70149254\n",
      " 0.76119403 0.7761194  0.77272727 0.72727273 0.83333333 0.81818182]\n",
      "76.88451680988994\n",
      "The accuracy of the Naive Bayes is 76.5\n",
      "[[73 24]\n",
      " [23 80]]\n"
     ]
    }
   ],
   "source": [
    "#MultinomialNB\n",
    "mnb = MultinomialNB(alpha=2)\n",
    "cv = cross_val_score(mnb,X_train,y_train,cv=kfold)\n",
    "print(cv)\n",
    "print(cv.mean()*100)\n",
    "mnb.fit(X_train,y_train)\n",
    "y_pred_mnb=mnb.predict(X_test)\n",
    "print('The accuracy of the Naive Bayes is', metrics.accuracy_score(y_pred_mnb,y_test)*100)\n",
    "cm=confusion_matrix(y_test, y_pred_mnb)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.73134328 0.80597015 0.73134328 0.80597015 0.74626866 0.7761194\n",
      " 0.7761194  0.71641791 0.78787879 0.75757576 0.72727273 0.75757576]\n",
      "75.99879390924168\n",
      "The accuracy of the Naive Bayes is 76.5\n",
      "[[73 24]\n",
      " [23 80]]\n"
     ]
    }
   ],
   "source": [
    "#Bernoulli NB\n",
    "bnb = BernoulliNB(alpha=10)\n",
    "cv = cross_val_score(bnb,X_train,y_train,cv=kfold)\n",
    "print(cv)\n",
    "print(cv.mean()*100)\n",
    "mnb.fit(X_train,y_train)\n",
    "y_pred_bnb=mnb.predict(X_test)\n",
    "print('The accuracy of the Naive Bayes is', metrics.accuracy_score(y_pred_bnb,y_test)*100)\n",
    "cm=confusion_matrix(y_test, y_pred_bnb)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.79104478 0.79104478 0.76119403 0.79104478 0.79104478 0.76119403\n",
      " 0.7761194  0.76119403 0.78787879 0.75757576 0.8030303  0.86363636]\n",
      "78.6333484094678\n",
      "The accuracy of the RandomForestClassifier is 76.5\n",
      "[[86 11]\n",
      " [36 67]]\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier\n",
    "rf = RandomForestClassifier(bootstrap=False, criterion='entropy', max_depth=30,\n",
    "                       max_features='log2', min_samples_leaf=2,\n",
    "                       n_estimators=500, random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "cv = cross_val_score(rf,X_train,y_train,cv=kfold)\n",
    "print(cv)\n",
    "print(cv.mean()*100)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "print('The accuracy of the RandomForestClassifier is',metrics.accuracy_score(y_pred_rf,y_test)*100)\n",
    "cm=confusion_matrix(y_test, y_pred_rf)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.73134328 0.79104478 0.7761194  0.7761194  0.71641791 0.7761194\n",
      " 0.79104478 0.79104478 0.74242424 0.71212121 0.74242424 0.75757576]\n",
      "75.86499321573949\n",
      "The accuracy of the Linear SVC is 72.0\n",
      "[[74 23]\n",
      " [33 70]]\n"
     ]
    }
   ],
   "source": [
    "#Linear SVC\n",
    "svcl = SVC(kernel = 'linear', random_state = 0, probability=True)\n",
    "svcl.fit(X_train, y_train)\n",
    "cv = cross_val_score(svcl,X_train,y_train,cv=kfold)\n",
    "print(cv)\n",
    "print(cv.mean()*100)\n",
    "y_pred_svcl = svcl.predict(X_test)\n",
    "print('The accuracy of the Linear SVC is',metrics.accuracy_score(y_pred_svcl,y_test)*100)\n",
    "cm=confusion_matrix(y_test, y_pred_svcl)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.73134328 0.79104478 0.73134328 0.82089552 0.71641791 0.80597015\n",
      " 0.76119403 0.74626866 0.77272727 0.6969697  0.77272727 0.81818182]\n",
      "76.37569727121965\n",
      "The accuracy of the Kernel SVC is 73.0\n",
      "[[90  7]\n",
      " [47 56]]\n"
     ]
    }
   ],
   "source": [
    "#rbf SVC\n",
    "from sklearn.svm import SVC\n",
    "svck = SVC(kernel = 'rbf', random_state = 0, probability=True)\n",
    "svck.fit(X_train, y_train)\n",
    "cv = cross_val_score(svck,X_train,y_train,cv=kfold)\n",
    "print(cv)\n",
    "print(cv.mean()*100)\n",
    "y_pred_svck = svck.predict(X_test)\n",
    "print('The accuracy of the Kernel SVC is',metrics.accuracy_score(y_pred_svck,y_test)*100)\n",
    "cm=confusion_matrix(y_test, y_pred_svck)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71641791 0.79104478 0.80597015 0.7761194  0.76119403 0.73134328\n",
      " 0.76119403 0.82089552 0.71212121 0.74242424 0.83333333 0.8030303 ]\n",
      "77.12573496155585\n",
      "The accuracy of the Voting Classifier is 77.5\n",
      "[[73 24]\n",
      " [21 82]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.75      0.76        97\n",
      "           1       0.77      0.80      0.78       103\n",
      "\n",
      "    accuracy                           0.78       200\n",
      "   macro avg       0.78      0.77      0.77       200\n",
      "weighted avg       0.78      0.78      0.77       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#VCLF \n",
    "voting_clf = VotingClassifier(estimators = [('bnb',bnb),('mnb',mnb),('gnb', gnb),\n",
    "                                            ('rf',rf),('svck',svck),('svcl',svcl)], voting = 'soft') \n",
    "voting_clf.fit(X_train, y_train)\n",
    "cv = cross_val_score(voting_clf,X_train,y_train,cv=kfold)\n",
    "print(cv)\n",
    "print(cv.mean()*100)\n",
    "y_pred_vclf = voting_clf.predict(X_test)\n",
    "print('The accuracy of the Voting Classifier is',metrics.accuracy_score(y_pred_vclf,y_test)*100)\n",
    "cm=confusion_matrix(y_test, y_pred_vclf)\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_pred_vclf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note : Voting classifier is having only highest accuracy w.r.t to the rest of the algos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a pickle file for the Multinomial Naive Bayes model\n",
    "filename = 'voting_clf.pkl'\n",
    "pickle.dump(voting_clf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
